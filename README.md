# PV_ENcoNet
3d detection model in point cloud
## Demo
![image](https://github.com/XYunaaa/PV_ENcoNet/blob/master/fig/01.gif)
![image](https://github.com/XYunaaa/PV_ENcoNet/blob/master/fig/19.gif)
![image](https://github.com/XYunaaa/PV_ENcoNet/blob/master/fig/20.gif)

## Introduction

### Workflow

![image](https://github.com/XYunaaa/PV_ENcoNet/blob/master/fig/model.png)

![img](https://github.com/XYunaaa/PV_ENcoNet/blob/master/fig/P-LocSt.png)

**PV_ENcoNet** is an efficient multi-sensor fusion based object detection model
that can be deployed on off-the-shelf edge computing device
for vehicular platform. PV_ENcoNet can achieve about 17.92 and 24.25 FPS on two different edge
computing platforms, and a detection accuracy comparable with
the state-of-the-art models on the KITTI public dataset.


## Evalution

![img](https://github.com/XYunaaa/PV_ENcoNet/blob/master/fig/res1.png)

## Install
Please refer to [Install.md](https://github.com/XYunaaa/PV_ENcoNet/blob/master/docs/Install.md) for the installation of PV_ENcoNet.

## Usage
Please refer to [Get_Started.md](https://github.com/XYunaaa/PV_ENcoNet/blob/master/docs/GetStarted.md) for the usage of PV_ENcoNet.
    
## Acknowledgments
We thanks for the opensource codebases:[OpenPCDet](https://github.com/open-mmlab/OpenPCDet) and [RandLA-Net](https://github.com/QingyongHu/RandLA-Net)
